{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 4**\n",
        "\n",
        "**This exercise will provide a valuable learning experience in working with text data and extracting features using various topic modeling algorithms. Key concepts such as Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA), lda2vec, and BERTopic.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks***.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission, and no requests will be answered. Manage your time accordingly.**\n"
      ],
      "metadata": {
        "id": "TU-pLW33lpcS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "\n",
        "**Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "VAZj4PHB70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08881c0-5024-4e22-f821-2bf172174d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of topics: 5\n",
            "Topics:\n",
            "(0, '0.031*\"movie\" + 0.031*\"political\" + 0.031*\"latest\" + 0.031*\"franchise\" + 0.031*\"session\"')\n",
            "(1, '0.047*\"thrilling\" + 0.047*\"match\" + 0.047*\"last\" + 0.047*\"announced\" + 0.047*\"night\"')\n",
            "(2, '0.031*\"movie\" + 0.031*\"session\" + 0.031*\"latest\" + 0.031*\"audiences\" + 0.031*\"political\"')\n",
            "(3, '0.089*\"health\" + 0.089*\"researchers\" + 0.089*\"treatment\" + 0.089*\"potential\" + 0.089*\"common\"')\n",
            "(4, '0.097*\"discussed\" + 0.097*\"leaders\" + 0.096*\"parliament\" + 0.096*\"budget\" + 0.096*\"session\"')\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models import CoherenceModel\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "news_articles = [\n",
        "    \"Political leaders discussed the budget in the parliament session.\",\n",
        "    \"The football match last night ended in a thrilling penalty shootout.\",\n",
        "    \"A new breakthrough in artificial intelligence was announced by a tech company.\",\n",
        "    \"The latest movie in the franchise has been well-received by audiences.\",\n",
        "    \"Researchers discovered a potential treatment for a common health condition.\"\n",
        "]\n",
        "\n",
        "# Tokenizing and preprocessing the input text\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokenized_articles = [word_tokenize(article.lower()) for article in news_articles]\n",
        "filtered_tokens = [[word for word in tokens if word.isalnum() and word not in stop_words] for tokens in tokenized_articles]\n",
        "\n",
        "# Creating the dictionary and corpus\n",
        "dictionary = corpora.Dictionary(filtered_tokens)\n",
        "corpus = [dictionary.doc2bow(tokens) for tokens in filtered_tokens]\n",
        "\n",
        "# Computing the coherence scores to determine optimal number of topics\n",
        "coherence_scores = {}\n",
        "for k in range(2, 6):  # Trying different numbers of topics\n",
        "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=k, random_state=42)\n",
        "    coherence_model = CoherenceModel(model=lda_model, texts=filtered_tokens, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_score = coherence_model.get_coherence()\n",
        "    coherence_scores[k] = coherence_score\n",
        "\n",
        "# Getting the optimal number of topics with the highest coherence score\n",
        "optimal_k = max(coherence_scores, key=coherence_scores.get)\n",
        "\n",
        "# Training LDA model with optimal number of topics\n",
        "optimal_lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=optimal_k, random_state=42)\n",
        "\n",
        "# Summarizing the topics\n",
        "topics = optimal_lda_model.print_topics(num_words=5)\n",
        "\n",
        "print(\"Optimal number of topics:\", optimal_k)\n",
        "print(\"Topics:\")\n",
        "for topic in topics:\n",
        "    print(topic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "\n",
        "**Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea147cda-35cf-464c-f420-65636f21eb1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of topics: 2\n",
            "Topics:\n",
            "(0, '-0.354*\"penalty\" + -0.354*\"shootout\" + -0.354*\"last\" + -0.354*\"match\" + -0.354*\"football\"')\n",
            "(1, '0.378*\"treatment\" + 0.378*\"potential\" + 0.378*\"common\" + 0.378*\"discovered\" + 0.378*\"researchers\"')\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import LsiModel\n",
        "from gensim.models import CoherenceModel\n",
        "import numpy as np\n",
        "\n",
        "def compute_coherence_score(model, texts, dictionary, coherence='c_v'):\n",
        "    coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence=coherence)\n",
        "    return coherence_model.get_coherence()\n",
        "\n",
        "news_articles = [\n",
        "    \"Political leaders discussed the budget in the parliament session.\",\n",
        "    \"The football match last night ended in a thrilling penalty shootout.\",\n",
        "    \"A new breakthrough in artificial intelligence was announced by a tech company.\",\n",
        "    \"The latest movie in the franchise has been well-received by audiences.\",\n",
        "    \"Researchers discovered a potential treatment for a common health condition.\"\n",
        "]\n",
        "\n",
        "# Tokenizing and preprocessing the text\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokenized_articles = [word_tokenize(article.lower()) for article in news_articles]\n",
        "filtered_tokens = [[word for word in tokens if word.isalnum() and word not in stop_words] for tokens in tokenized_articles]\n",
        "\n",
        "# Creating the dictionary and corpus\n",
        "dictionary = corpora.Dictionary(filtered_tokens)\n",
        "corpus = [dictionary.doc2bow(tokens) for tokens in filtered_tokens]\n",
        "\n",
        "# Computing the coherence scores to determine optimal number of topics\n",
        "coherence_scores = {}\n",
        "max_topics = min(len(news_articles), len(dictionary)) - 1  # Maximum number of topics\n",
        "for k in range(2, max_topics):\n",
        "    lsi_model = LsiModel(corpus=corpus, id2word=dictionary, num_topics=k)\n",
        "    coherence_score = compute_coherence_score(lsi_model, filtered_tokens, dictionary)\n",
        "    coherence_scores[k] = coherence_score\n",
        "\n",
        "# Getting the optimal number of topics with the highest coherence score\n",
        "optimal_k = max(coherence_scores, key=coherence_scores.get)\n",
        "\n",
        "# Training LSI model with optimal number of topics\n",
        "optimal_lsi_model = LsiModel(corpus=corpus, id2word=dictionary, num_topics=optimal_k)\n",
        "\n",
        "# Summarizing the topics\n",
        "topics = optimal_lsi_model.print_topics(num_words=5)\n",
        "\n",
        "print(\"Optimal number of topics:\", optimal_k)\n",
        "print(\"Topics:\")\n",
        "for topic in topics:\n",
        "    print(topic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "**Generate K topics by using lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "2CRuXfV570ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02fd2f9-c938-4a76-875c-b346a1f605ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence Score: 0.2407869499258611\n",
            "Topic 0: 0.083*\"a\" + 0.049*\"potential\" + 0.049*\"discovered\" + 0.049*\"treatment\" + 0.049*\"health\" + 0.049*\"researchers\" + 0.049*\"for\" + 0.049*\"common\" + 0.049*\"condition.\" + 0.017*\"in\"\n",
            "Topic 1: 0.087*\"the\" + 0.071*\"in\" + 0.054*\"a\" + 0.039*\"by\" + 0.024*\"franchise\" + 0.024*\"been\" + 0.024*\"new\" + 0.024*\"latest\" + 0.024*\"session.\" + 0.024*\"announced\"\n"
          ]
        }
      ],
      "source": [
        "from gensim import corpora, models\n",
        "import pyLDAvis\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "try:\n",
        "    import seaborn\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "\n",
        "news_articles = [\n",
        "    \"Political leaders discussed the budget in the parliament session.\",\n",
        "    \"The football match last night ended in a thrilling penalty shootout.\",\n",
        "    \"A new breakthrough in artificial intelligence was announced by a tech company.\",\n",
        "    \"The latest movie in the franchise has been well-received by audiences.\",\n",
        "    \"Researchers discovered a potential treatment for a common health condition.\"\n",
        "]\n",
        "\n",
        "# Tokenize and preprocess text data\n",
        "tokenized_text = [text.lower().split() for text in news_articles]\n",
        "\n",
        "# Create dictionary and corpus\n",
        "dictionary = corpora.Dictionary(tokenized_text)\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_text]\n",
        "\n",
        "# Train LDA model\n",
        "lda_model = models.LdaModel(corpus, id2word=dictionary, num_topics=2, passes=10)\n",
        "\n",
        "# Compute coherence score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=tokenized_text, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "\n",
        "print(\"Coherence Score:\", coherence_lda)\n",
        "\n",
        "# Extract topics\n",
        "topics = lda_model.print_topics(num_words=10)\n",
        "\n",
        "# Print topics\n",
        "for topic in topics:\n",
        "    print(\"Topic {}: {}\".format(topic[0], topic[1]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "**Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "eb3ceba0352445b596885383c7455304",
            "29fe9bf9049d4717a9e511fc26d814c9",
            "bb455a749fa641b89638094c37585bc4",
            "d93c06626f334ee59a661c29b9d897c7",
            "b3139e112ce24fdca458f06e881b2500",
            "d15007ae30264e988079dd9de0f641da",
            "dec86cc04f2040cc8415b3e50db497b4",
            "4db3669320c34d59962c8501a006d7d6",
            "cc95fc5400b24c4e9f6669e0dacc764e",
            "cf30efe261284bcda4e350bac66f0f4f",
            "1579f53a01a54a0083dede9b3cdf1512"
          ]
        },
        "outputId": "26ea7880-a0bc-4320-9fd4-33dca1c0a4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.25.2)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.8.33)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.5.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.2.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.2)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.6.1)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.15.0)\n",
            "Requirement already satisfied: cython<3,>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (0.29.37)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (24.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.38.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (9.4.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.58.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (4.10.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.99)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-03-30 02:39:27,156 - BERTopic - Embedding - Transforming documents to embeddings.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb3ceba0352445b596885383c7455304"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-03-30 02:39:27,657 - BERTopic - Embedding - Completed ✓\n",
            "2024-03-30 02:39:27,661 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
            "2024-03-30 02:39:30,092 - BERTopic - Dimensionality - Completed ✓\n",
            "2024-03-30 02:39:30,095 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
            "2024-03-30 02:39:30,165 - BERTopic - Cluster - Completed ✓\n",
            "2024-03-30 02:39:30,194 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
            "2024-03-30 02:39:30,225 - BERTopic - Representation - Completed ✓\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Topic  Count                     Name  \\\n",
            "0     -1     10  -1_the_in_new_potential   \n",
            "\n",
            "                                      Representation  \\\n",
            "0  [the, in, new, potential, of, for, by, warn, w...   \n",
            "\n",
            "                                 Representative_Docs  \n",
            "0  [Celebrations erupted across the country after...  \n",
            "False\n",
            "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
          ]
        }
      ],
      "source": [
        "!pip install bertopic\n",
        "from bertopic import BERTopic\n",
        "\n",
        "#I have used more data. Bert Requires more data to work correctly\n",
        "news_articles = [\n",
        "    \"Political leaders discussed the budget in the parliament session.\",\n",
        "    \"The football match last night ended in a thrilling penalty shootout.\",\n",
        "    \"A new breakthrough in artificial intelligence was announced by a tech company.\",\n",
        "    \"The latest movie in the franchise has been well-received by audiences.\",\n",
        "    \"Researchers discovered a potential treatment for a common health condition.\",\n",
        "    \"The company's stock saw a significant increase in value following the announcement.\",\n",
        "    \"A new study sheds light on the long-term effects of climate change.\",\n",
        "    \"The city unveiled plans for a new public transportation system.\",\n",
        "    \"Celebrations erupted across the country after the team won the championship.\",\n",
        "    \"Experts warn of potential cybersecurity threats in the upcoming elections.\"\n",
        "]\n",
        "\n",
        "# Creating BERTopic model\n",
        "topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
        "\n",
        "# Fitting the model\n",
        "topics, probs = topic_model.fit_transform(news_articles)\n",
        "\n",
        "# Getting topic information\n",
        "freq = topic_model.get_topic_info()\n",
        "print(freq.head(5))\n",
        "\n",
        "# Getting the top words for a specific topic\n",
        "print(topic_model.get_topic(0))\n",
        "\n",
        "# Getting the top topics\n",
        "print(topic_model.topics_[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Question (5 Points)\n",
        "\n",
        "**Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details.**\n",
        "\n",
        "**This question will compensate for any points deducted in this exercise. Maximum marks for the exercise is 40 points.**"
      ],
      "metadata": {
        "id": "d89ODUx3jjJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "'''\n",
        "#LDA produced conversation topics about politics, health studies, movies, and sporting events. There was some overlap between the political and cinematic themes, but overall the ideas were understandable.\n",
        "\n",
        "#The themes generated by LSA were clearly comprehensible and centered around health studies and sporting activities.\n",
        "#The subjects did not overlap or remain unclear.\n",
        "\n",
        "#lda2vec offered entertainment (movies/franchises) and issues pertaining to health research and possible cures.\n",
        "#Although there was some room for interpretation, cohesion might use some work.\n",
        "\n",
        "#Documents were grouped by BERTopic using representations derived from typical documents and frequently occurring terms.\n",
        "#While other clusters indicated more narrowly focused themes, the texts in the '-1' cluster most likely covered a\n",
        "#wide range of subjects.\n",
        "\n",
        "#LSA and LDA produced clear and interpretable topics with minimal redundancy and high coherence, making them suitable choices for this dataset.\n",
        "\n",
        "#lda2vec and BERTopic offered more advanced techniques leveraging word embeddings, but their topics were less interpretable and coherent in this context.\n",
        "#For this LSA and LDA appear to provide the most effective and interpretable results.\n",
        "'''"
      ],
      "metadata": {
        "id": "OK34nZtojhmm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "a18bb2ab-3bf2-4029-9b32-9eb0e5a6be59"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#LDA produced conversation topics about politics, health studies, movies, and sporting events. There was some overlap between the political and cinematic themes, but overall the ideas were understandable.\\n\\n#The themes generated by LSA were clearly comprehensible and centered around health studies and sporting activities. \\n#The subjects did not overlap or remain unclear.\\n\\n#lda2vec offered entertainment (movies/franchises) and issues pertaining to health research and possible cures. \\n#Although there was some room for interpretation, cohesion might use some work.\\n\\n#Documents were grouped by BERTopic using representations derived from typical documents and frequently occurring terms. \\n#While other clusters indicated more narrowly focused themes, the texts in the '-1' cluster most likely covered a \\n#wide range of subjects.\\n\\n#LSA and LDA produced clear and interpretable topics with minimal redundancy and high coherence, making them suitable choices for this dataset.\\n\\n#lda2vec and BERTopic offered more advanced techniques leveraging word embeddings, but their topics were less interpretable and coherent in this context.\\n#For this LSA and LDA appear to provide the most effective and interpretable results.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment.\n",
        "\n",
        "Consider the following points in your response:\n",
        "\n",
        "**Learning Experience:** Describe your overall learning experience in working with text data and extracting features using various topic modeling algorithms. Did you understand these algorithms and did the implementations helped in grasping the nuances of feature extraction from text data.\n",
        "\n",
        "**Challenges Encountered:** Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "The Exercise is really challenging. It improved my overall experience in the LSA, LDA, BERT and LDA2VEC. My Overall experience is good while doing this exercise. /\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb3ceba0352445b596885383c7455304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29fe9bf9049d4717a9e511fc26d814c9",
              "IPY_MODEL_bb455a749fa641b89638094c37585bc4",
              "IPY_MODEL_d93c06626f334ee59a661c29b9d897c7"
            ],
            "layout": "IPY_MODEL_b3139e112ce24fdca458f06e881b2500"
          }
        },
        "29fe9bf9049d4717a9e511fc26d814c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d15007ae30264e988079dd9de0f641da",
            "placeholder": "​",
            "style": "IPY_MODEL_dec86cc04f2040cc8415b3e50db497b4",
            "value": "Batches: 100%"
          }
        },
        "bb455a749fa641b89638094c37585bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db3669320c34d59962c8501a006d7d6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc95fc5400b24c4e9f6669e0dacc764e",
            "value": 1
          }
        },
        "d93c06626f334ee59a661c29b9d897c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf30efe261284bcda4e350bac66f0f4f",
            "placeholder": "​",
            "style": "IPY_MODEL_1579f53a01a54a0083dede9b3cdf1512",
            "value": " 1/1 [00:00&lt;00:00,  8.12it/s]"
          }
        },
        "b3139e112ce24fdca458f06e881b2500": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d15007ae30264e988079dd9de0f641da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec86cc04f2040cc8415b3e50db497b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4db3669320c34d59962c8501a006d7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc95fc5400b24c4e9f6669e0dacc764e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf30efe261284bcda4e350bac66f0f4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1579f53a01a54a0083dede9b3cdf1512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}